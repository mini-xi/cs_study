# 데이터 수집

# 1. 데이터 수집

## 1. 데이터 처리 프로세스의 이해


![1](https://user-images.githubusercontent.com/97429679/163860108-50f5ff07-0d11-4ace-8f59-19b14818db37.jpg)

[http://i-bada.blogspot.com/2012/04/blog-post_3992.html](http://i-bada.blogspot.com/2012/04/blog-post_3992.html)

### 1. 데이터 처리 영역

- 데이터 분석을 위한 기초 데이터를 정의하고 수집 및 저장, 분석하기 수월하도록 물리적인 환경을 제공하는 영역 ( 데이터소스, 수집, 저장, 처리)

### 2. 데이터 분석 영역

- 저장되어 있는 데이터를 추출하여 분석 목적과 방법에 맞게 가공한후, 데이터 분석을 직접 수행하고 그 결과를 표현하는 영역 (데이터분석, 데이터표현)

## 2. 데이터 수집

### 1. 비즈니스 도메인과 원천 데이터 정보 수집

1) 비즈니스 도메인

- 비즈니스 모델, 비즈니스 용어집, 비즈니스 프로세스로 부터 정보 습득
- 도메인 전문가 인터뷰를 통한 정보 습득

2) 원천 데이터 정보

- 데이터 수집 가능성, 데이터의 보안, 데이터의 정확성, 수집 난이도, 수집 비용등의 기초 자료 수집

### 2. 내.외부 데이터 수집

1) 데이터의 종류

![2](https://user-images.githubusercontent.com/97429679/163860114-55f95270-736a-4ef2-b84f-0d99b16580ee.jpg)

2) 데이터 수집 방법

![3](https://user-images.githubusercontent.com/97429679/163860128-236ebf13-a2cf-4282-98b0-79252052a107.jpg)

### 3. 데이터 유형에 따른 데이터 수집 기술

1) 정형 데이터

- ETL(Extract Transform Load)
    - 수집 대상의 데이터를 추출, 변환하여 데이터 웨어하우스에 저장하는 기술이다.
- FTP(File Transfer Protocal)
    - TCP/IP나 UDP 프로토콜을 통해 서버로부터 파일을 송수신하는 기술이다.
    - 동작 방식이 직관적이고, 파일을 빠른 속도로 한꺼번에 주고 받을수 있다.
        

        ![4](https://user-images.githubusercontent.com/97429679/163860139-64aca170-1dbf-4838-8876-79e7916ddbf6.jpg)
        
        [https://hack-cracker.tistory.com/133](https://hack-cracker.tistory.com/133)
        
    - 데이터 제어 연결(Control Connection) :  사용자 계정 및 암호 등의 정보와 파일 전송 명령 및 결과 등 처리
    - 데이터 전송 연결(Data Connection) : 실제 파일 송수신 작업
- 스쿱(Sqoop)
    - 커넥터를 사용하여 관계형 데이터 베이스의 데이터를 하둡 파일시스템으로 전송하는 방법이다.
    - 가져온 데이터들을 하둡 맵리듀스(Mapreduce)로 변환하고 변환된 데이터들을 다시 관계형 데이터베이스로 내보낼수 있다.
        

        ![그림1](https://user-images.githubusercontent.com/97429679/163860152-162719a7-bbb7-4a95-8cb2-a2df525433d4.png)
       
        [https://excelsior-cjh.tistory.com/56](https://excelsior-cjh.tistory.com/56)
        
- API(Application Programming Interface) : 시스템간 연동을 통해 실시간으로 데이터를 수신할수 있도록 기능을 제공하는 인터페이스이다.
- DBToDB : 데이터베이스 관리시스템 간 데이터를 동기화 또는 전송하는 방법이다.

2) 비정형 데이터

- 크롤링(Crawling) : 인터넷상에서 제공되는 다양한 웹사이트로 부터 소셜 네트워크 정보, 뉴스, 게시판 등에서 웹 문서 및 정보를 수집하는 기술이다.
    - 스크래핑(Scraping)과의 차이 : 크롤링은 URL, 키워드 등을 수집하고 스크래핑은 필요한 특정 데이터를 긁어오는것으로 스크래핑을 수행하기 위해서는 먼저 크롤링 작업이 수행되어야 한다.
- Open API : 응용 프로그램을 통해 실시간으로 데이터를 수신할수 있도록 공개된 API이다.
- 척와(Chukwa) : 분산 시스템으로부터 데이터를 수집하고 하둡 파일 시스템에 저장하며 실시간으로 분석할수 있는 기능을 제공하는 기술이다.
- 카프카(Kafka) :  대용량 실시간 로그처리를 위한 분산 스트리밍 플랫폼기술이다.

3) 반정형 데이터

- 플럼(Flume)
    - 분산환경에서 대용량의 로그데이터를 수집 전송하고 분석하는 기능을 제공하는 솔루션이다.
    - 로그데이터 외에도 네트워크 트래픽 데이터, 소셜 미디어 데이터, 이메일 메시지등 대량의 이벤트 데이터 전송을 위해 사용된다.
    - 스트링 데이터 흐름에 기반을 둔 간단하고 유연한 구조이다.
        

        ![5](https://user-images.githubusercontent.com/97429679/163860164-827ab46c-f433-4812-95a6-4fa64b8f0983.jpg)
        
        [https://www.nextree.co.kr/p2704/](https://www.nextree.co.kr/p2704/)
        
    - 플럼은 소스, 채널, 싱크로 구성된다. 소스는 웬시데이터 소스와 연결되며, 소스로부터 들어오는 데이터는 큐의 구조를 갖는 채널로 들어간 후 , 싱크를 통해 목표 시스템에 전달된다.
- 스크라이브(Scribe) : 다수의 수집 대상 서버로부터 실시간 데이터를 수집, 분산 시스템에 데이터를 저장하는 기능을 제공한다.
- 센싱 : 센서로부터 수집 및 생성된 데이터를 네트워크를 통해 활용하여 수집하는 기능을 제공한다.
- 스트리밍 : 네트워크를 통해 센서 데이터 및 오디오, 비디오 등의 미디어 데이터를 실시간으로 수진하는 기술이다.
