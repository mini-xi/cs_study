데이터 파이프라인은 로우데이터를 수집하고, 처리하여 시각화하거나 분석에 사용하기까지 데이터가 거치는 자동화된 과정과 그때 사용되는 툴들이라고 볼 수 있다. 즉 데이터를 수집하는 곳에서부터 저장하려하는 목적지까지 데이터가 이동하는 경로이다. 이러한 데이터 파이프라인에 대해 알아보려 한다.

<br><br>

## 데이터 파이프라인

데이터는 그 종류가 다양하고, 사용될 목적 또한 다양하기때문에 수집한 데이터를 적재하고 끝나는 것이 아니라 적절히 처리되는 과정을 거치기 마련이다. 이러한 과정을 자동화한 것이 데이터 파이프라인이고 그 때 사용되는 툴들도 함께 의미하기도 한다.

<img src="https://qlik.imgix.net//us/-/media/images/global-us/site-content/etl/etl-pipeline/elt-pipeline-infographic.png?w=1376&h=971&fit=crop&auto=format&fit=max&dpr=1">

출처 : https://www.qlik.com/us/data-integration/data-pipeline

데이터의 종류와 양이 점차 많아지면서 파이프라인의 구성도 변화했다. 기존의 파이프라인은 로우 데이터를 추출, 처리해서 데이터 웨어하우스에 저장했다. 하지만 데이터 웨어하우스는 주로 스케일 업 방식으로만 성능을 향상할 수 있었기때문에 데이터의 양이 많아지면서 한계에 부딪혔다. 그 대안으로써 사용된 것이 분산 스토리지였다.

안전성 등이 보장되기때문에 데이터 웨어하우스를 포기하는 방식보다는, 분산 스토리지를 함께 사용하며 집계 처리된 중요한, 혹은 작은 데이터만을 웨어하우스에 저장하는 방식으로 발전하게 된다.

<br><br>

## ETL / ELT Pipeline

데이터 파이프라인 중 한 형태인 ETL은 데이터를 Extract, Transform, Load하는 과정을 일컽는다. 로우 데이터로부터 추출(Extract)한 데이터들이 변형(Transform)되어 최종적으로 스토리지에 저장(Load)된다.

1. 데이터 수집(Extract)
   데이터베이스 내의 데이터, 파일 서버의 로그 파일, 모바일 애플리케이션의 이벤트 데이터 등 데이터는 다양한 디바이스에서 다양한 형태로 생겨난다.

   데이터를 수집하는 방식에 따라 벌크(bulk)형 데이터 수집과 스트리밍(streaming)형 데이터 수집으로 나뉜다.

   - 벌크형 : 이미 어딘가에 존재하는 데이터를 정리해 추출하는 방식. 정기적으로 데이터를 추출할 때 주로 사용한다.
   - 스트리밍형 : 계속해서 생성되는 데이터를 끊임없이 수집하는 방식. 주로 모바일 애플리케이션이나 임베디드 장비 등의 데이터를 수집하는데 사용된다.

2. 데이터 처리(Transform)
   수집한 데이터를 스토리지에 저장하기 적합한 형태로 처리하는 작업을 진행하는 단계이다. 데이터를 수집하는 것뿐만 아니라 처리하는 방법 또한 방식에 따라 나뉘어 진다.

   - 배치(batch) 처리 : 대량의 데이터를 효율적으로 가공하기 위해 사용되는 방식. 데이터 분석을 위해 대량의 데이터가 필요할 때 주로 사용한다.
   - 스트림(stream) 처리 : 스트리밍형으로 수집한 데이터를 실시간으로 처리하기 위해 사용하는 방식. 30분 단위 등 실시간으로 데이터를 처리해 실시간 처리를 지향하는 데이터베이스에 저장한다. 현재 어떤 일이 있는지 파악하기에 용이하다.

3. 데이터 저장(Load)
   기존에는 데이터 웨어하우스에 저장되었다면, 빅데이터의 경우에는 분산 스토리지를 거쳐 웨어하우스에 저장되게 된다. NoSQL 데이터베이스를 분산 스토리지로 사용할 수도 있고, 클라우드 서비스를 사용하기도 한다.

   분산 스토리지에 저장된 데이터들은 MapReduce나 Hadoop같은 분산 데이터 처리 프레임워크를 이용해 데이터 웨어하우스에 저장된다.

빅데이터의 경우 다양한 형태의 데이터를 저장해야한다. 따라서 우선 추출한 데이터를 저장해 데이터 레이크(Data Lake)를 만들고 이후에 사용 용도에 따라 변형하는 ELT 프로세스를 이용하는 경우도 있다.

<img src="https://miro.medium.com/max/630/1*-6tNymvTTqGIWJlzQHwBaw.png">

출처:https://towardsdatascience.com/how-i-redesigned-over-100-etl-into-elt-data-pipelines-c58d3a3cb3c

<br><br>

## 참고

빅데이터를 지탱하는 기술, 니시다 케이스케, 제이펍, 2021(전자책)
