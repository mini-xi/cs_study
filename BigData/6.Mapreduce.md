# MapReduce란?
![MapReduce](https://images.velog.io/images/kimdukbae/post/3777016a-7ad2-43c3-aa36-b765e2fc85d1/image.png)<br><br>
***하둡의 계산을 담당***<br><br>
HDFS와 마찬가지로 master-slave 구조를 가짐.<br>
![m-s](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FJH0J5%2FbtqVtceNe9c%2FwTKZ0PCb5FswcSksfPtBq1%2Fimg.png)<br><br>
***MapReduce Layer*** : MapReduce를 수행하기 위한 Layer<br>
***Job*** : 클라이언트가 수행하는 작업의 기본단위<br>
***Job Tracker*** : 사용자로부터 Job을 요청 받고 Task Tracker에 작업 할당<br>
***Task Tracker*** : Job Tracker로부터 할당 받은 작업을 Map-Reduce하여 결과 반환<br><br>

# Map과 Reduce 단계<br>
- ***Map*** : input 데이터를 가공하여 사용자가 원하는 정보를 Key-Value쌍으로 변환시킴. 이때, input크기를 'split'이라고 하는데 하둡은 split마다 'Map Task'를 생성하고, 그 split에 있는 각 레코드를 사용자 정의 맵 함수로 처리함<br>
- ***Reduce*** : 중간 산출물을 key를 기준으로 각 Reduce로 분배하고, 사용자가 정의한 방법으로 각 Key에 관련된 정보를 추출함<br><br>
ex) WordCount<br>
![flow](https://velog.velcdn.com/images%2Fspdlqjfire%2Fpost%2F9188daef-72f9-4658-878f-7ccafefd7ca2%2Fimage.png)<br><br>
- 입력 데이터는 1개<br>
- Map 단계에서 한 줄에 있는 단어의 수를 계산해 한 줄씩 출력. 위 그림에서 보듯이 Map(line_num, line)함수를 통해 Deer, 1과 같은 Key-Value가 생성<br>
- 연관성있는 데이터들끼리 모아 정렬<br>
- Reduce는 Map의 출력 결과 데이터를 집계<br>
- 최종적인 결과물로 각 단어에 대한 개수가 출력, HDFS에 파일로 저장됨